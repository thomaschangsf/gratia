{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d8444f",
   "metadata": {},
   "source": [
    "# Part1: Manual Load Fasttext Model\n",
    "- Does **NOT** use pybay for model discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017b42f",
   "metadata": {},
   "source": [
    "### Apply Fasttext model on Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcf2524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+----------+\n",
      "|text                                                                    |prediction|\n",
      "+------------------------------------------------------------------------+----------+\n",
      "|No its you then dont say its free shipment its not exist at all dumb ass|insult    |\n",
      "|Never will buy shit from your bitch ass and giving you a horrible review|insult    |\n",
      "|I don't think I've ever seen someone so bad at their job as you are.    |insult    |\n",
      "|Shut up scammer , I know what you are trying to do                      |clean     |\n",
      "+------------------------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "sc: pyspark.context.SparkContext = SparkContext.getOrCreate()\n",
    "session: pyspark.sql.session.SparkSession = spark\n",
    "\n",
    "mock_text = [\n",
    "        (\"No its you then dont say its free shipment its not exist at all dumb ass\", 1),\n",
    "        (\"Never will buy shit from your bitch ass and giving you a horrible review\", 1),\n",
    "        (\"I don't think I've ever seen someone so bad at their job as you are.\", 1),\n",
    "        (\"Shut up scammer , I know what you are trying to do\", 1) \n",
    "]\n",
    "\n",
    "df1 = spark.createDataFrame(data=mock_text, schema = ['text', 'prediction'])\n",
    "\n",
    "import fasttext_classifier_simple \n",
    "\n",
    "udf_predict = udf(fasttext_classifier_simple.predict)\n",
    "\n",
    "sc.addFile('/Users/thchang/Documents/dev/git/nlp/m2m/m2m_model/projects/offensive_content_detection/insult/model/model-insult-base.bin')\n",
    "sc.addFile('/Users/thchang/Documents/dev/git/pyspark_env/fasttext_classifier_simple.py')\n",
    "\n",
    "df2 = df1.withColumn('prediction', udf_predict(col('text')))\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8e6ed",
   "metadata": {},
   "source": [
    "### fasttext_classifier_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "512f2558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import fasttext\r\n",
      "\r\n",
      "model = fasttext.load_model('/Users/thchang/Documents/dev/git/nlp/m2m/m2m_model/projects/offensive_content_detection/insult/model/model-insult-base.bin')\r\n",
      "\r\n",
      "def predict(msg):\r\n",
      "\tpred = model.predict([msg])[0][0][0]\r\n",
      "\tpred = pred.replace('__label__', '')\r\n",
      "\treturn str(pred)\r\n"
     ]
    }
   ],
   "source": [
    "!cat /Users/thchang/Documents/dev/git/pyspark_env/fasttext_classifier_simple.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ced4e",
   "metadata": {},
   "source": [
    "# Part 2: Model Inference Via Pybay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd3ce9",
   "metadata": {},
   "source": [
    "#### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "450717cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+\n",
      "|text                                                                    |\n",
      "+------------------------------------------------------------------------+\n",
      "|No its you then dont say its free shipment its not exist at all dumb ass|\n",
      "|Never will buy shit from your bitch ass and giving you a horrible review|\n",
      "|I don't think I've ever seen someone so bad at their job as you are.    |\n",
      "|Shut up scammer , I know what you are trying to do                      |\n",
      "|Have a good day                                                         |\n",
      "+------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import col, udf\n",
    "import fasttext_classifier_pybay\n",
    "\n",
    "\n",
    "sc: pyspark.context.SparkContext = SparkContext.getOrCreate()\n",
    "session: pyspark.sql.session.SparkSession = spark\n",
    "\n",
    "mock_text = [\n",
    "        (\"No its you then dont say its free shipment its not exist at all dumb ass\", 1),\n",
    "        (\"Never will buy shit from your bitch ass and giving you a horrible review\", 1),\n",
    "        (\"I don't think I've ever seen someone so bad at their job as you are.\", 1),\n",
    "        (\"Shut up scammer , I know what you are trying to do\", 1),\n",
    "        (\"Have a good day\", 1)\n",
    "]\n",
    "\n",
    "df_raw = spark.createDataFrame(data=mock_text, schema = ['text', 'prediction'])\n",
    "\n",
    "df_raw.select('text').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a993055c",
   "metadata": {},
   "source": [
    "#### Use Pybay for Model Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd0856f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-25 15:18:40,824 - pybay.core.factory.swift.swift_registry [MainThread  ] [INFO ]  Loading cached model data from path /Users/thchang/.cache/pybay/swift_models.json\n",
      "2021-05-25 15:18:40,830 - pybay.core.factory.swift.swift_registry [MainThread  ] [DEBUG]  Downloading model metadata from https://os-object.vip.ebayc3.com/v1/KEY_45b296c6f29b4462b5aaedcac5255d99/pynlp-dev/swift_models_v5.json?temp_url_sig=a575d8ed65cff49368f3ca64959dff64f54c6d49&temp_url_expires=1625308181\n",
      "2021-05-25 15:18:41,571 - pybay.core.factory.swift.swift_registry [MainThread  ] [INFO ]  Models metadata version 0.5\n",
      "2021-05-25 15:18:41,579 - pybay.core.factory.swift.swift_registry [MainThread  ] [INFO ]  Found 165 models.\n",
      "2021-05-25 15:18:41,581 - pybay.core.helpers.telemetry.telemetry [MainThread  ] [DEBUG]  Pushing 4 prometheus metrics\n",
      "2021-05-25 15:18:42,252 - pybay.core.helpers.telemetry.telemetry [MainThread  ] [DEBUG]  Pushing 1 prometheus metrics\n",
      "2021-05-25 15:18:43,029 - pybay.core.factory.swift.swift_model_data [MainThread  ] [INFO ]  Checking model files in /Users/thchang/.cache/pybay/fa0b6f6e-a9ad-4ec9-87d4-f64c28b39c0f, downloading from Swift if necessary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c3673b7f5c405691560e87fed304f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "downloading:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-25 15:18:43,051 - pybay.core.factory.swift.swift_model_data [MainThread  ] [DEBUG]  File /Users/thchang/.cache/pybay/fa0b6f6e-a9ad-4ec9-87d4-f64c28b39c0f/model-insult-base.bin exists, skipping: model-insult-base.bin\n",
      "2021-05-25 15:18:43,054 - pybay.core.factory.swift.swift_model_data [MainThread  ] [DEBUG]  Model files are ready.\n",
      "2021-05-25 15:18:43,055 - pybay.core.helpers.telemetry.telemetry [MainThread  ] [DEBUG]  Pushing 1 prometheus metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path=/Users/thchang/.cache/pybay/fa0b6f6e-a9ad-4ec9-87d4-f64c28b39c0f/model-insult-base.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/thchang/.cache/pybay/fa0b6f6e-a9ad-4ec9-87d4-f64c28b39c0f/model-insult-base.bin'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pybay.core\n",
    "registry = pybay.core.Registry()\n",
    "#registry.list_models(\"m2m*\")\n",
    "\n",
    "def parse_model_metadata(model_name: str):\n",
    "    meta_data=registry.get_artifact(model_name)\n",
    "\n",
    "    base_path = registry.download_model_data(model_name)\n",
    "\n",
    "    configuration = meta_data.factories['microservice'].microservice_data.configuration[\"models\"][0]\n",
    "\n",
    "    model_path=str(base_path) + configuration[\"model_path\"].replace('/models/', '/')\n",
    "    print(f'model_path={model_path}')\n",
    "    \n",
    "    return model_path, configuration\n",
    "\n",
    "model_path, configuration = parse_model_metadata(\"m2m-offensive-content-insult-0.1\")\n",
    "\n",
    "model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c01350",
   "metadata": {},
   "source": [
    "#### Apply Pybay FastTextClassifier on DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55f1fbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+----------+\n",
      "|text                                                                    |prediction|\n",
      "+------------------------------------------------------------------------+----------+\n",
      "|No its you then dont say its free shipment its not exist at all dumb ass|insult    |\n",
      "|Never will buy shit from your bitch ass and giving you a horrible review|insult    |\n",
      "|I don't think I've ever seen someone so bad at their job as you are.    |insult    |\n",
      "|Shut up scammer , I know what you are trying to do                      |insult    |\n",
      "|Have a good day                                                         |clean     |\n",
      "+------------------------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pybay_model_tokenizer import *\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "CLASSIFIER = None\n",
    "\n",
    "def get_classifier():\n",
    "    global CLASSIFIER\n",
    "    if CLASSIFIER is None:\n",
    "        \n",
    "        tokenizer = SpacyTokenizer(name=configuration[\"spacy_model\"])\n",
    "\n",
    "        CLASSIFIER = FastTextClassifier(\n",
    "            model_path=model_path, \\\n",
    "            tokenizer= tokenizer, \\\n",
    "            lowercase=True)\n",
    "\n",
    "    return CLASSIFIER\n",
    "\n",
    "def spacy_tokenize(msg):\n",
    "    model = get_classifier()\n",
    "    return CLASSIFIER.classify(msg).tags[0]\n",
    "\n",
    "tokenize_udf = session.udf.register(\"tokenize_udf\", spacy_tokenize)\n",
    "\n",
    "df_inferenced = df_raw.withColumn('prediction', tokenize_udf(col('text')))\n",
    "\n",
    "df_inferenced.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06a702",
   "metadata": {},
   "source": [
    "#### Cat Pybay File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4b07f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import Optional, Iterable, Mapping, List, Union\r\n",
      "from pathlib import Path\r\n",
      "\r\n",
      "import fasttext\r\n",
      "\r\n",
      "#Cannot serialize SPACY!!! https://futurice.com/blog/classifying-text-with-fasttext-in-pyspark\r\n",
      "#import spacy  \r\n",
      "#from spacy import load\r\n",
      "\r\n",
      "from pybay.types.nlp.tokenizer import Tokenizer, Tokenization\r\n",
      "from pybay.types.nlp.tagger import TextClassifier, TextClassificationResult\r\n",
      "\r\n",
      "\r\n",
      "class SpacyTokenizer(Tokenizer):\r\n",
      "    \"\"\"\r\n",
      "    Simple tokenizer based on Spacy\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    #nlp: spacy.language.Language   \r\n",
      "    name: str\r\n",
      "\r\n",
      "    def __init__(self, name: str):\r\n",
      "        \"\"\"\r\n",
      "        Ctor\r\n",
      "        :param name: Spacy Name of tokenizer (e.g. ``en_core_web_sm``)\r\n",
      "        \"\"\"\r\n",
      "        #TWC self.nlp = spacy.load(name, disable=['ner', 'tagger', 'parser', 'textcat'])\r\n",
      "        self.name = name\r\n",
      "\r\n",
      "    def tokenize(self, sentence: str) -> Tokenization:\r\n",
      "        #return Tokenization(tokens=[token.text for token in self.nlp(sentence)])\r\n",
      "        return Tokenization(tokens=[token for token in sentence.lower().split(' ')])\r\n",
      "\r\n",
      "    def tokenize_batch(self, sentences: Iterable[str]) -> Iterable[Tokenization]:\r\n",
      "        #yield from (self.tokenize(sentence) for sentence in sentences)\r\n",
      "        yield from ( sentence.lower() for sentence in sentences)\r\n",
      "\r\n",
      "    def __str__(self):\r\n",
      "        return f\"SpacyTokenizer({self.name})\"\r\n",
      "\r\n",
      "\r\n",
      "class FastTextClassifier(TextClassifier):\r\n",
      "    \"\"\"\r\n",
      "    Wrapping a Fasttext classifier for pybay.types\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    model: fasttext.FastText\r\n",
      "    \"\"\" Loaded fasttext model \"\"\"\r\n",
      "\r\n",
      "    tokenizer: Tokenizer\r\n",
      "    \"\"\" Tokenizer to use \"\"\"\r\n",
      "\r\n",
      "    lowercase: bool\r\n",
      "    \"\"\" whether to lowercase the input \"\"\"\r\n",
      "\r\n",
      "    name: str\r\n",
      "    \"\"\" Name of tokenizer in __str__ \"\"\"\r\n",
      "\r\n",
      "    def __init__(self, model_path: str, tokenizer: Tokenizer, lowercase: bool = True):\r\n",
      "        \"\"\"\r\n",
      "        Ctor\r\n",
      "        :param model_path: Path to fasttext model.bin file\r\n",
      "        :param tokenizer:  PyBay Tokenizer object to use for tokenization\r\n",
      "        :param lowercase:  Whether to lowercase the input before sending it to the model\r\n",
      "        \"\"\"\r",
      "\r\n",
      "\r\n",
      "        self.model = fasttext.load_model(model_path)\r\n",
      "        #self.model = fasttext.load_model(str(Path(model_path)))\r\n",
      "        self.tokenizer = tokenizer\r\n",
      "        self.lowercase =  lowercase\r\n",
      "        self.name = Path(model_path).name\r\n",
      "\r\n",
      "    def __str__(self):\r\n",
      "        return f\"FastTextClassifier({self.name})\"\r\n",
      "\r\n",
      "    def classify(self, sentence: str, *, k: int = 0, context: Optional[Mapping[str, str]] = None) \\\r\n",
      "            -> TextClassificationResult:\r\n",
      "        preprocessed_sentence = self._preprocess_input(sentence)\r\n",
      "        prediction = self.model.predict(preprocessed_sentence, k=max(k, 1))  # default value for k is 0 in PyBay, but 1 in FastText\r\n",
      "        tags = [self._postprocess_tagname(tagname) for tagname in prediction[0]]\r\n",
      "        result = TextClassificationResult(sentence=preprocessed_sentence,\r\n",
      "                                          tags=tags,\r\n",
      "                                          probs=dict(zip(tags, prediction[1])))\r\n",
      "        return result\r\n",
      "\r\n",
      "    def classify_batch(self, sentences: Iterable[str], *,\r\n",
      "                       k: int = 0,\r\n",
      "                       contexts: Optional[Iterable[Mapping[str, str]]] = None) -> Iterable[TextClassificationResult]:\r\n",
      "        yield from (self.classify(sentence) for sentence in sentences)\r\n",
      "\r\n",
      "    def get_tagset(self) -> List[str]:\r\n",
      "        return [self._postprocess_tagname(tagname) for tagname in self.model.get_labels()]\r\n",
      "\r\n",
      "    def _preprocess_input(self, sentence):\r\n",
      "        \"\"\"\r\n",
      "        Preprocess the input -- tokenize, and put to lower case if required\r\n",
      "        :param sentence:\r\n",
      "        :return:\r\n",
      "        \"\"\"\r\n",
      "        tokenized = self.tokenizer.tokenize(sentence)\r\n",
      "        result = \" \".join(tokenized.tokens).replace(\"\\n\", \" \")\r\n",
      "        if self.lowercase:\r\n",
      "            return result.lower()\r\n",
      "        return result\r\n",
      "\r\n",
      "    def _postprocess_tagname(self, tagname: str):\r\n",
      "        \"\"\"\r\n",
      "        Postprocess tag names -- remove __label__ prefix if present\r\n",
      "        :param tagname: Fasttext tag name\r\n",
      "        :return: Tagname without __label__ prefix\r\n",
      "        \"\"\"\r\n",
      "        if tagname.startswith(\"__label__\"):\r\n",
      "            return tagname[9:]\r\n",
      "        return tagname"
     ]
    }
   ],
   "source": [
    "!cat /Users/thchang/Documents/dev/git/pyspark_env/pybay_model_tokenizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd67bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e0e9ae1",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, label in df3.rdd.map(lambda row: (row[0], row[1])).collect():\n",
    "    print(f'{text} --> {label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
